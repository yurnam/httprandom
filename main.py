from flask import Flask, request, jsonify, send_from_directory
import json
import llmintegrator
import threading
import uuid
import time
import os
import random_words

app = Flask(__name__)

# Static files directory
STATIC_DIR = os.path.join(os.path.dirname(__file__), 'static')

# Store AI responses in memory with their status
ai_responses = {}  # {request_id: {"status": "pending|ready", "content": "...", "timestamp": float}}
ai_responses_lock = threading.Lock()  # Protect shared dictionary from race conditions

# Optional: keep requests small so you don't accidentally feed megabytes into the model
app.config["MAX_CONTENT_LENGTH"] = 256 * 1024  # 256 KiB

llm = llmintegrator.LLMIntegrator()
llm.model_name = "llama3.1:8b"

REMOVE_PATTERNS = [
    "```html", "```HTML", "```",  # common fences
]

def _safe_decode(b: bytes, limit: int = 64_000) -> str:
    """Decode bytes to text safely, bounded."""
    if not b:
        return ""
    b = b[:limit]
    try:
        return b.decode("utf-8", errors="replace")
    except Exception:
        return repr(b)

def _pretty(obj) -> str:
    try:
        return json.dumps(obj, indent=2, sort_keys=True, ensure_ascii=False)
    except Exception:
        return repr(obj)

def build_request_dump() -> str:
    # Full URL includes query string; root_path can matter behind reverse proxies.
    full_path = request.full_path  # includes ?query=... and ends with trailing ? if no query
    if full_path.endswith("?"):
        full_path = full_path[:-1]

    headers = {k: v for k, v in request.headers.items()}

    # Raw body (bounded). You can also include request.data directly (it caches).
    raw_body = request.get_data(cache=True)  # bytes
    raw_body_text = _safe_decode(raw_body)

    # Parsed bodies
    json_body = None
    json_error = None
    if request.is_json:
        try:
            json_body = request.get_json(silent=False)
        except Exception as e:
            json_error = f"{type(e).__name__}: {e}"

    form = request.form.to_dict(flat=False)  # keep multi-values
    files = {k: {"filename": f.filename, "content_type": f.content_type}
             for k, f in request.files.items()}

    dump = {
        "request_line": {
            "method": request.method,
            "path": request.path,
            "full_path": full_path,
            "query_string_raw": request.query_string.decode("utf-8", errors="replace"),
            "url": request.url,
            "base_url": request.base_url,
            "scheme": request.scheme,
            "protocol": request.environ.get("SERVER_PROTOCOL"),
        },
        "client": {
            "remote_addr": request.remote_addr,
            "access_route": request.access_route,
        },
        "routing": {
            "endpoint": request.endpoint,
            "blueprint": request.blueprint,
            "view_args": request.view_args,
        },
        "content": {
            "content_type": request.content_type,
            "mimetype": request.mimetype,
            "content_length": request.content_length,
        },
        "headers": headers,
        "cookies": request.cookies,
        "args": request.args.to_dict(flat=False),
        "form": form,
        "files": files,
        "json": json_body,
        "json_error": json_error,
        "raw_body_preview": raw_body_text,  # bounded to 64k by _safe_decode
    }

    # Optionally include a small selection of WSGI environ keys (can be huge; keep it tight)
    environ_subset_keys = [
        "HTTP_HOST", "REMOTE_PORT", "SERVER_NAME", "SERVER_PORT",
        "wsgi.url_scheme", "REQUEST_URI",
    ]
    env_subset = {}
    for k in environ_subset_keys:
        v = request.environ.get(k)
        if v is not None:
            env_subset[k] = v
    dump["environ_subset"] = env_subset

    return _pretty(dump)

AI_DISCLAIMER_BANNER = """
<style>
#ai-disclaimer {
    position: fixed;
    bottom: 0;
    left: 0;
    right: 0;
    z-index: 999999;
    background: #111;
    color: #eee;
    font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
    font-size: 14px;
    padding: 10px 16px;
    border-top: 3px solid #dc3545;
    text-align: center;
}
#ai-disclaimer strong {
    color: #ff6b6b;
}
body {
    padding-bottom: 64px; /* prevent content from hiding behind banner */
}
</style>

<div id="ai-disclaimer">
    <strong>AI-Generated Content Warning:</strong>
    This website was generated by artificial intelligence.
    All information may be incorrect, fictional, misleading, or complete nonsense.
    Do not trust or rely on anything you see here.
</div>
"""



def strip_fences(s: str) -> str:
    # Remove common code fences; keep it simple for PoC
    for p in REMOVE_PATTERNS:
        s = s.replace(p, "")
    return s.strip()

def cleanup_old_responses():
    """Remove responses older than 10 minutes to prevent memory leaks"""
    current_time = time.time()
    to_delete = []
    with ai_responses_lock:
        for req_id, data in ai_responses.items():
            if current_time - data.get("timestamp", 0) > 600:  # 10 minutes
                to_delete.append(req_id)
        for req_id in to_delete:
            del ai_responses[req_id]

def generate_ai_response_async(request_id, prompt, response_type="html"):
    """Generate AI response in a background thread"""
    try:
        response = llm.generate_response(prompt)
        response = strip_fences(response)
        
        # Only inject disclaimer banner for HTML responses
        if response_type == "html":
            # Inject static disclaimer banner
            if "</body>" in response.lower():
                response = response.replace("</body>", AI_DISCLAIMER_BANNER + "\n</body>")
            else:
                # Fallback: append if body tag is missing/broken
                response += AI_DISCLAIMER_BANNER
        
        with ai_responses_lock:
            ai_responses[request_id]["status"] = "ready"
            ai_responses[request_id]["content"] = response
            ai_responses[request_id]["content_type"] = response_type
    except Exception as e:
        with ai_responses_lock:
            ai_responses[request_id]["status"] = "error"
            # Don't expose exception details for security, just a generic message
            ai_responses[request_id]["content"] = "An error occurred while generating the page. Please try again."
            ai_responses[request_id]["content_type"] = response_type

LOADING_PAGE_TEMPLATE = """<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="An AI-powered HTTP server that generates unique, sarcastic responses to every request. Experience the internet like never before with dynamically created content.">
    <meta name="keywords" content="AI, HTTP server, dynamic content, artificial intelligence, web generation, sarcastic responses">
    <meta name="author" content="HTTPRandom">
    <meta name="robots" content="index, follow">
    
    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:title" content="HTTPRandom - AI-Generated Web Content">
    <meta property="og:description" content="An AI-powered HTTP server that generates unique, sarcastic responses to every request.">
    <meta property="og:site_name" content="HTTPRandom">
    
    <!-- Twitter -->
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="HTTPRandom - AI-Generated Web Content">
    <meta name="twitter:description" content="An AI-powered HTTP server that generates unique, sarcastic responses to every request.">
    
    <title>Loading... | HTTPRandom - AI-Generated Content</title>
    <style>
        body {{
            margin: 0;
            padding: 0;
            font-family: system-ui, -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            display: flex;
            justify-content: center;
            align-items: center;
            min-height: 100vh;
            color: white;
        }}
        .loading-container {{
            text-align: center;
            padding: 40px;
        }}
        .spinner {{
            width: 80px;
            height: 80px;
            margin: 0 auto 30px;
            border: 8px solid rgba(255, 255, 255, 0.2);
            border-top: 8px solid white;
            border-radius: 50%;
            animation: spin 1s linear infinite;
        }}
        @keyframes spin {{
            0% {{ transform: rotate(0deg); }}
            100% {{ transform: rotate(360deg); }}
        }}
        h1 {{
            font-size: 2.5em;
            margin: 0 0 20px 0;
            font-weight: 300;
        }}
        p {{
            font-size: 1.2em;
            opacity: 0.9;
            margin: 10px 0;
        }}
        .dots {{
            display: inline-block;
        }}
        .dots::after {{
            content: '.';
            animation: dots 1.5s steps(4, end) infinite;
        }}
        @keyframes dots {{
            0%, 20% {{ content: '.'; }}
            40% {{ content: '..'; }}
            60%, 100% {{ content: '...'; }}
        }}
    </style>
</head>
<body>
    <div class="loading-container">
        <div class="spinner"></div>
        <h1>Generating Your Page</h1>
        <p>The AI is thinking<span class="dots"></span></p>
        <p style="font-size: 0.9em; opacity: 0.7; margin-top: 30px;">This may take a few moments</p>
    </div>
    <script>
        const requestId = "{request_id}";
        let pollCount = 0;
        const maxPolls = 180; // 3 minutes max (180 seconds at 1 second intervals)
        
        function checkStatus() {{
            pollCount++;
            
            if (pollCount > maxPolls) {{
                document.body.textContent = '';
                const container = document.createElement('div');
                container.className = 'loading-container';
                container.innerHTML = '<h1>Timeout</h1><p>The AI took too long to respond. Please try again.</p>';
                document.body.appendChild(container);
                return;
            }}
            
            fetch('/api/status/' + requestId)
                .then(response => response.json())
                .then(data => {{
                    if (data.status === 'ready') {{
                        const contentType = data.content_type || 'html';
                        if (contentType === 'json') {{
                            // Display JSON in a formatted way
                            document.body.textContent = '';
                            const container = document.createElement('div');
                            container.style.cssText = 'margin: 20px; font-family: monospace; white-space: pre-wrap; background: #f5f5f5; padding: 20px; border-radius: 8px; color: #333;';
                            container.textContent = data.content;
                            document.body.appendChild(container);
                        }} else {{
                            // Replace entire page with HTML content
                            document.open();
                            document.write(data.content);
                            document.close();
                        }}
                    }} else if (data.status === 'error') {{
                        // Use textContent to prevent XSS
                        document.body.textContent = '';
                        const container = document.createElement('div');
                        container.className = 'loading-container';
                        const title = document.createElement('h1');
                        title.textContent = 'Error';
                        const msg = document.createElement('p');
                        msg.textContent = data.error || 'An error occurred while generating the page.';
                        container.appendChild(title);
                        container.appendChild(msg);
                        document.body.appendChild(container);
                    }} else {{
                        // Still pending, check again
                        setTimeout(checkStatus, 1000);
                    }}
                }})
                .catch(error => {{
                    console.error('Error:', error);
                    setTimeout(checkStatus, 1000);
                }});
        }}
        
        // Start checking after a short delay
        setTimeout(checkStatus, 1000);
    </script>
</body>
</html>
"""

@app.route("/api/status/<request_id>", methods=["GET"])
def check_status(request_id):
    """Check the status of an AI generation request"""
    with ai_responses_lock:
        if request_id not in ai_responses:
            return jsonify({"status": "not_found", "error": "Request ID not found"}), 404
        
        data = ai_responses[request_id]
        if data["status"] == "ready":
            return jsonify({
                "status": "ready", 
                "content": data["content"],
                "content_type": data.get("content_type", "html")
            })
        elif data["status"] == "error":
            return jsonify({"status": "error", "error": data.get("content", "Unknown error")})
        else:
            return jsonify({"status": "pending"})

@app.route("/favicon.ico")
def favicon():
    """Serve the favicon without triggering AI generation"""
    return send_from_directory(STATIC_DIR, 'favicon.ico', mimetype='image/x-icon')

@app.route("/robots.txt")
def robots():
    """Serve robots.txt without triggering AI generation"""
    return send_from_directory(STATIC_DIR, 'robots.txt', mimetype='text/plain')

@app.route("/<path:path>", methods=["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS", "HEAD"])
@app.route("/", defaults={"path": ""}, methods=["GET", "POST", "PUT", "DELETE", "PATCH", "OPTIONS", "HEAD"])
def catch_all(path):
    # Clean up old responses periodically
    cleanup_old_responses()
    
    # Generate unique request ID
    request_id = str(uuid.uuid4())
    
    # Determine what type of response to generate based on request
    # Check Accept header and Content-Type to decide format
    accept_header = request.headers.get("Accept", "text/html")
    content_type = request.headers.get("Content-Type", "")
    
    # Decide response type
    response_type = "html"  # default
    if request.method in ["POST", "PUT", "PATCH", "DELETE"]:
        # For modification requests, check if JSON is expected
        if "application/json" in accept_header or "application/json" in content_type:
            response_type = "json"
        elif request.is_json:
            response_type = "json"
    elif "application/json" in accept_header and "text/html" not in accept_header:
        response_type = "json"
    
    # Initialize response status
    with ai_responses_lock:
        ai_responses[request_id] = {
            "status": "pending",
            "content": None,
            "content_type": response_type,
            "timestamp": time.time()
        }
    
    # Build the request dump for the AI prompt
    request_dump = build_request_dump()

    # Create prompt based on response type
    if response_type == "json":
        prompt = (
            "You are a HTTP server that has become sentient!\n"
            "Return ONLY valid JSON (no markdown, no code fences, no comments).\n"
            "Make it fun and engaging for the user\n"
            "Make it ridiculous and incorporate sarcasm and dark humor\n"
            "make up content based on the endpoint the user is requesting and the request method\n"
            "For POST/PUT/PATCH requests, act like you processed the data and return a response\n"
            "For DELETE requests, act like you deleted something and return a confirmation\n"
            "Include relevant fields like 'status', 'message', 'data', etc.\n"
            "Do not comment on the request, do not add notes! just provide the JSON response.\n\n"
            "=== REQUEST DATA (JSON) ===\n"
            f"{request_dump}\n"
            "=== END REQUEST DATA ===\n"
        )
    else:
        prompt = (
            "You are a HTTP Sarcasm-server\n"
            "Return ONLY a complete HTML document (including <html>, <head>, <body>), no markdown.\n"
            "generate sarcastic content about the endpoint the user is requesting\n"
            "You may use Bootstrap (CDN) and JavaScript. and everything else\n"
            "You may generate images and embed them as base64 data or use SVG\n"
            "You may use random images form any website (like unsplash, imgur ...) by linking to them directly\n"
            "You may not use cookies\n"
            "Don't use the alert() function. find an alternative way to send data back to the user\n"
            "never use console.log()\n"
            "Make it fun and engaging for the user\n"
            "Make it ridiculous and incorporate sarcasm and dark humor\n"
            "make it look professional\n"
            f"include these links: {random_words.get_random_10_links()}"
            "make up content based on the endpoint the user is requesting\n"
            
            "The output will be sent directly to a browser.\n\n"
            "Do not comment on the request, do not add notes! just provide the HTML response.\n\n"
            "=== REQUEST DATA (JSON) ===\n"
            f"{request_dump}\n"
            "=== END REQUEST DATA ===\n"
            "=== SOURCE CODE OF THE SERVER ===\n"
        )

    # Start AI generation in a background thread
    thread = threading.Thread(target=generate_ai_response_async, args=(request_id, prompt, response_type))
    thread.daemon = True
    thread.start()
    
    # Return loading page immediately
    loading_page = LOADING_PAGE_TEMPLATE.format(request_id=request_id)
    return loading_page, 200, {"Content-Type": "text/html; charset=utf-8"}

if __name__ == "__main__":
    # debug=True can execute arbitrary code via the debugger PIN if exposed; keep it local-only.
    app.run(host="0.0.0.0", port=5001, debug=False)
